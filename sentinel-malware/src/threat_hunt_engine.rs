//! Module 46: ThreatHuntEngine — Proactive Threat Hunting Platform
//!
//! World-class proactive threat hunting engine enabling analyst-driven and
//! automated threat discovery through hypothesis-based queries, IOC sweeps,
//! stacking analysis, and long-tail anomaly detection across all telemetry.
//!
//! ## Features
//!
//! - **Hypothesis-driven hunts**: Define structured hypotheses with expected
//!   evidence types, data source mappings, and kill-chain progression
//! - **Query language**: SQL-like filter/sort/aggregate engine over telemetry
//!   (processes, files, network, registry, DNS, auth logs, loaded modules)
//! - **Anomaly hunts**: Z-score & IQR deviation detection across baselines
//!   with configurable sensitivity per data source
//! - **IOC sweeps**: Mass-scan all telemetry for specific indicators (hashes,
//!   IPs, domains, filenames, registry keys) with parallel matching
//! - **Scheduled hunts**: Recurring hunts on configurable cadence with delta
//!   re-scanning of new telemetry since last execution
//! - **Evidence collection**: Artifact preservation with BLAKE3 hashing and
//!   chain-of-custody tracking
//! - **MITRE ATT&CK playbooks**: Pre-built hunt playbooks per technique with
//!   expected findings and false-positive guidance
//! - **Stacking analysis**: Frequency analysis — the "least common" technique
//!   for finding adversary artifacts hiding in the long tail
//! - **Long-tail analysis**: Modified Z-score and Grubbs' test to identify
//!   anomalous processes, connections, and files
//! - **Hunt metrics**: Effectiveness, time-to-detection, finding rates,
//!   false positive ratios, and analyst productivity tracking
//!
//! ## Memory Breakthroughs Used
//!
//! - **#1  HierarchicalState** — O(log n) hunt history checkpoints
//! - **#2  TieredCache** — Hot cache for active findings, cold for archived
//! - **#3  ReversibleComputation** — Recompute finding scores from evidence
//! - **#5  StreamAccumulator** — Streaming hunt rate & finding statistics
//! - **#6  MemoryMetrics** — Bounded memory for all telemetry stores
//! - **#461 DifferentialStore** — Delta updates for hunt state changes
//! - **#569 PruningMap** — Auto-expire old findings by age/priority
//! - **#592 DedupStore** — Deduplicate identical evidence across hunts
//! - **#627 SparseMatrix** — Technique × data source hit frequency matrix
//!
//! ## MITRE ATT&CK Coverage
//!
//! Enables hunting across all 14 ATT&CK tactics with pre-built playbooks
//! for the most impactful techniques per tactic.

use crate::types::*;
use sentinel_core::tiered_cache::TieredCache;
use sentinel_core::hierarchical::HierarchicalState;
use sentinel_core::reversible::ReversibleComputation;
use sentinel_core::streaming::StreamAccumulator;
use sentinel_core::differential::DifferentialStore;
use sentinel_core::sparse::SparseMatrix;
use sentinel_core::pruning::PruningMap;
use sentinel_core::dedup::DedupStore;
use sentinel_core::MemoryMetrics;

use std::collections::{HashMap, HashSet, VecDeque};
use std::sync::atomic::{AtomicBool, AtomicU64, Ordering};
use std::sync::Arc;
use parking_lot::RwLock;
use tracing::{info, warn, debug};

// ── Constants ───────────────────────────────────────────────────────────────

const HISTORY_LEVELS: u32 = 8;
const HISTORY_PER_LEVEL: usize = 64;
const FINDING_CACHE_MAX: usize = 100_000;
const STATS_WINDOW: usize = 256;
const MAX_TELEMETRY_PER_SOURCE: usize = 500_000;
const MAX_FINDINGS_PER_HUNT: usize = 10_000;
const STACKING_RARE_PCT: f64 = 1.0;
const LONG_TAIL_ZSCORE: f64 = 3.0;
const MEMORY_BUDGET: usize = 128 * 1024 * 1024;

// ── Suspicious Process Names (baseline hunts) ───────────────────────────────

const SUSPICIOUS_PROCESSES: &[&str] = &[
    "mimikatz", "lazagne", "rubeus", "sharphound", "bloodhound",
    "covenant", "cobalt", "metasploit", "msfconsole", "msfvenom",
    "psexec", "wmic", "certutil", "bitsadmin", "mshta",
    "regsvr32", "rundll32", "cscript", "wscript",
    "ncat", "socat", "chisel", "ligolo",
    "crackmapexec", "impacket", "smbexec", "wmiexec", "dcomexec",
    "evil-winrm", "pypykatz", "secretsdump", "ntdsutil",
    "procdump", "nanodump", "handlekatz", "lsassy",
    "kekeo", "safetykatz", "sharpwmi", "sharpdpapi",
];

// ── Suspicious Network Ports ────────────────────────────────────────────────

const SUSPICIOUS_PORTS: &[u16] = &[
    4444, 5555, 6666, 7777, 8888, 9999,
    1234, 31337, 12345, 54321,
    4443, 8443, 8080, 8081,
    3389, 5900, 5985, 5986,
    445, 135, 139,
];

// ── Hunt Status ─────────────────────────────────────────────────────────────

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, serde::Serialize, serde::Deserialize)]
pub enum HuntStatus {
    Draft,
    Active,
    Paused,
    Completed,
    Archived,
    Failed,
}

// ── Hunt Type ───────────────────────────────────────────────────────────────

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, serde::Serialize, serde::Deserialize)]
pub enum HuntType {
    Hypothesis,
    IocSweep,
    AnomalyDriven,
    Stacking,
    LongTail,
    Scheduled,
    MitrePlaybook,
    SigmaRule,
}

// ── Data Source ──────────────────────────────────────────────────────────────

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, serde::Serialize, serde::Deserialize)]
pub enum DataSource {
    ProcessTelemetry,
    FileTelemetry,
    NetworkTelemetry,
    RegistryTelemetry,
    DnsTelemetry,
    AuthLogs,
    CommandLine,
    FileHashes,
    LoadedModules,
    ScheduledTasks,
    ServiceChanges,
}

// ── Finding Severity ────────────────────────────────────────────────────────

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, serde::Serialize, serde::Deserialize)]
pub enum FindingSeverity {
    Informational,
    Low,
    Medium,
    High,
    Critical,
}

impl FindingSeverity {
    pub fn score(&self) -> f64 {
        match self {
            Self::Informational => 0.1,
            Self::Low => 0.25,
            Self::Medium => 0.5,
            Self::High => 0.75,
            Self::Critical => 1.0,
        }
    }
}

// ── IOC Type ────────────────────────────────────────────────────────────────

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, serde::Serialize, serde::Deserialize)]
pub enum IocType {
    Sha256, Sha1, Md5, Blake3,
    Ipv4, Ipv6, Domain, Url,
    Filename, FilePath, RegistryKey,
    MutexName, PipeName, ServiceName,
}

// ── Filter Operator ─────────────────────────────────────────────────────────

#[derive(Debug, Clone, Copy, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
pub enum FilterOp {
    Eq, NotEq, Contains, NotContains,
    StartsWith, EndsWith, Regex,
    Gt, Lt, Gte, Lte,
    In, NotIn, Exists,
}

// ── Hunt Configuration ──────────────────────────────────────────────────────

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct HuntConfig {
    pub max_findings_per_hunt: usize,
    pub max_telemetry_per_source: usize,
    pub stacking_rare_threshold_pct: f64,
    pub long_tail_zscore_threshold: f64,
    pub auto_archive_after_days: u32,
    pub evidence_preservation: bool,
    pub auto_escalate_critical: bool,
    pub memory_budget_bytes: usize,
}

impl Default for HuntConfig {
    fn default() -> Self {
        Self {
            max_findings_per_hunt: MAX_FINDINGS_PER_HUNT,
            max_telemetry_per_source: MAX_TELEMETRY_PER_SOURCE,
            stacking_rare_threshold_pct: STACKING_RARE_PCT,
            long_tail_zscore_threshold: LONG_TAIL_ZSCORE,
            auto_archive_after_days: 90,
            evidence_preservation: true,
            auto_escalate_critical: true,
            memory_budget_bytes: MEMORY_BUDGET,
        }
    }
}

// ── Query Filter ────────────────────────────────────────────────────────────

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct QueryFilter {
    pub field: String,
    pub operator: FilterOp,
    pub value: String,
    pub and_filters: Vec<QueryFilter>,
    pub or_filters: Vec<QueryFilter>,
}

impl Default for QueryFilter {
    fn default() -> Self {
        Self {
            field: String::new(), operator: FilterOp::Eq,
            value: String::new(), and_filters: vec![], or_filters: vec![],
        }
    }
}

// ── Hunt Query ──────────────────────────────────────────────────────────────

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct HuntQuery {
    pub id: String,
    pub description: String,
    pub data_source: DataSource,
    pub filter: QueryFilter,
    pub sort_by: Option<String>,
    pub sort_desc: bool,
    pub limit: Option<u32>,
    pub group_by: Option<String>,
}

// ── IOC Entry ───────────────────────────────────────────────────────────────

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct IocEntry {
    pub ioc_type: IocType,
    pub value: String,
    pub source: String,
    pub confidence: f64,
    pub added_at: i64,
}

// ── Hunt ────────────────────────────────────────────────────────────────────

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct Hunt {
    pub id: String,
    pub name: String,
    pub description: String,
    pub hunt_type: HuntType,
    pub status: HuntStatus,
    pub hypothesis: Option<String>,
    pub data_sources: Vec<DataSource>,
    pub queries: Vec<HuntQuery>,
    pub mitre_techniques: Vec<String>,
    pub created_at: i64,
    pub started_at: Option<i64>,
    pub completed_at: Option<i64>,
    pub analyst: String,
    pub findings: Vec<HuntFinding>,
    pub artifacts_collected: u64,
    pub records_searched: u64,
    pub tags: Vec<String>,
    pub schedule_cron: Option<String>,
    pub last_run: Option<i64>,
    pub run_count: u32,
    pub ioc_list: Vec<IocEntry>,
}

// ── Evidence ────────────────────────────────────────────────────────────────

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct Evidence {
    pub evidence_type: String,
    pub source: DataSource,
    pub data: HashMap<String, String>,
    pub timestamp: i64,
    pub hash: Option<String>,
    pub preserved: bool,
    pub custody_chain: Vec<String>,
}

// ── Hunt Finding ────────────────────────────────────────────────────────────

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct HuntFinding {
    pub id: String,
    pub hunt_id: String,
    pub severity: FindingSeverity,
    pub title: String,
    pub description: String,
    pub evidence: Vec<Evidence>,
    pub mitre_technique: Option<String>,
    pub confidence: f64,
    pub timestamp: i64,
    pub affected_assets: Vec<String>,
    pub recommended_actions: Vec<String>,
    pub false_positive: bool,
    pub escalated: bool,
    pub related_finding_ids: Vec<String>,
}

// ── Stacking Result ─────────────────────────────────────────────────────────

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct StackingResult {
    pub field: String,
    pub value: String,
    pub count: u64,
    pub percentage: f64,
    pub is_rare: bool,
    pub z_score: f64,
    pub first_seen: i64,
    pub last_seen: i64,
    pub associated_assets: Vec<String>,
}

// ── Long-Tail Result ────────────────────────────────────────────────────────

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct LongTailResult {
    pub field: String,
    pub value: String,
    pub count: u64,
    pub z_score: f64,
    pub is_outlier: bool,
    pub median_count: f64,
    pub mad: f64,
    pub associated_assets: Vec<String>,
}

// ── Hunt Playbook ───────────────────────────────────────────────────────────

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct HuntPlaybook {
    pub id: String,
    pub name: String,
    pub mitre_technique: String,
    pub mitre_tactic: String,
    pub description: String,
    pub hypothesis: String,
    pub data_sources_required: Vec<DataSource>,
    pub queries: Vec<HuntQuery>,
    pub expected_findings: Vec<String>,
    pub false_positive_guidance: Vec<String>,
    pub references: Vec<String>,
    pub difficulty: HuntDifficulty,
    pub estimated_duration_mins: u32,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, serde::Serialize, serde::Deserialize)]
pub enum HuntDifficulty { Beginner, Intermediate, Advanced, Expert }

// ── Hunt Statistics ─────────────────────────────────────────────────────────

#[derive(Debug, Clone, Default, serde::Serialize, serde::Deserialize)]
pub struct HuntStats {
    pub total_hunts: u64,
    pub active_hunts: u64,
    pub completed_hunts: u64,
    pub failed_hunts: u64,
    pub total_findings: u64,
    pub critical_findings: u64,
    pub high_findings: u64,
    pub escalated_findings: u64,
    pub false_positives: u64,
    pub records_searched: u64,
    pub artifacts_collected: u64,
    pub ioc_sweeps_completed: u64,
    pub stacking_analyses: u64,
    pub long_tail_analyses: u64,
    pub total_queries_executed: u64,
    pub avg_findings_per_hunt: f64,
    pub false_positive_rate: f64,
    pub hunts_by_type: HashMap<String, u64>,
    pub findings_by_technique: HashMap<String, u64>,
}

// ═══════════════════════════════════════════════════════════════════════════
// ThreatHuntEngine — Main Engine
// ═══════════════════════════════════════════════════════════════════════════

pub struct ThreatHuntEngine {
    config: HuntConfig,
    running: Arc<AtomicBool>,

    // ── Breakthrough #1: Hierarchical hunt history ──
    hunt_history: RwLock<HierarchicalState<HuntStats>>,

    // ── Breakthrough #2: Tiered finding cache ──
    finding_cache: TieredCache<String, HuntFinding>,

    // ── Breakthrough #3: Reversible score computation ──
    score_computer: RwLock<ReversibleComputation<f64, f64>>,

    // ── Breakthrough #5: Streaming hunt rate ──
    hunt_rate: RwLock<StreamAccumulator<f64, HuntStats>>,

    // ── Breakthrough #6: Memory bounds ──
    metrics: MemoryMetrics,

    // ── Breakthrough #461: Differential hunt state ──
    hunt_diffs: RwLock<DifferentialStore<String, String>>,

    // ── Breakthrough #569: Pruning old findings ──
    recent_findings: RwLock<PruningMap<String, HuntFinding>>,

    // ── Breakthrough #592: Deduplicate evidence ──
    finding_dedup: RwLock<DedupStore<String, Vec<u8>>>,

    // ── Breakthrough #627: Technique × source frequency ──
    technique_source_matrix: RwLock<SparseMatrix<String, String, u64>>,

    // ── Hunt state ──
    hunts: RwLock<HashMap<String, Hunt>>,
    playbooks: RwLock<HashMap<String, HuntPlaybook>>,

    // ── Telemetry stores (bounded ring buffers) ──
    telemetry_process: RwLock<VecDeque<HashMap<String, String>>>,
    telemetry_network: RwLock<VecDeque<HashMap<String, String>>>,
    telemetry_file: RwLock<VecDeque<HashMap<String, String>>>,
    telemetry_auth: RwLock<VecDeque<HashMap<String, String>>>,
    telemetry_registry: RwLock<VecDeque<HashMap<String, String>>>,

    // ── IOC database for sweeps ──
    ioc_database: RwLock<HashMap<IocType, HashSet<String>>>,

    // ── Stats ──
    stats: RwLock<HuntStats>,
    alerts: RwLock<VecDeque<MalwareAlert>>,
    total_queries: AtomicU64,
}

// ═══════════════════════════════════════════════════════════════════════════
// Implementation
// ═══════════════════════════════════════════════════════════════════════════

impl ThreatHuntEngine {
    pub fn new() -> Self {
        Self::with_config(HuntConfig::default())
    }

    pub fn with_config(config: HuntConfig) -> Self {
        let metrics = MemoryMetrics::new(config.memory_budget_bytes);

        let finding_cache = TieredCache::new(FINDING_CACHE_MAX)
            .with_metrics(metrics.clone(), "threat_hunt_findings");

        let score_computer = ReversibleComputation::new(
            2048,
            |scores: &[f64]| {
                if scores.is_empty() { return 0.0; }
                scores.iter().sum::<f64>() / scores.len() as f64
            },
        );

        let hunt_rate = StreamAccumulator::new(
            STATS_WINDOW,
            HuntStats::default(),
            |acc: &mut HuntStats, findings_per_hunt: &[f64]| {
                for &f in findings_per_hunt {
                    acc.total_findings += f as u64;
                    acc.completed_hunts += 1;
                }
            },
        );

        Self {
            running: Arc::new(AtomicBool::new(false)),
            finding_cache,
            score_computer: RwLock::new(score_computer),
            hunt_rate: RwLock::new(hunt_rate),
            metrics,
            hunt_history: RwLock::new(HierarchicalState::new(HISTORY_LEVELS, HISTORY_PER_LEVEL)),
            hunt_diffs: RwLock::new(DifferentialStore::new().with_max_chain(256)),
            recent_findings: RwLock::new(PruningMap::new(FINDING_CACHE_MAX)),
            finding_dedup: RwLock::new(DedupStore::new()),
            technique_source_matrix: RwLock::new(SparseMatrix::new(0u64)),
            hunts: RwLock::new(HashMap::new()),
            playbooks: RwLock::new(HashMap::new()),
            telemetry_process: RwLock::new(VecDeque::with_capacity(100_000)),
            telemetry_network: RwLock::new(VecDeque::with_capacity(100_000)),
            telemetry_file: RwLock::new(VecDeque::with_capacity(100_000)),
            telemetry_auth: RwLock::new(VecDeque::with_capacity(50_000)),
            telemetry_registry: RwLock::new(VecDeque::with_capacity(50_000)),
            ioc_database: RwLock::new(HashMap::new()),
            stats: RwLock::new(HuntStats::default()),
            alerts: RwLock::new(VecDeque::with_capacity(1000)),
            total_queries: AtomicU64::new(0),
            config,
        }
    }

    // ── Lifecycle ───────────────────────────────────────────────────────────

    pub fn start(&self) {
        self.running.store(true, Ordering::SeqCst);
        self.metrics.register_component(
            "telemetry_stores",
            self.config.max_telemetry_per_source * 5 * 256,
        );
        info!("ThreatHuntEngine started: budget={}MB",
            self.config.memory_budget_bytes / (1024 * 1024));
    }

    pub fn stop(&self) {
        self.running.store(false, Ordering::SeqCst);
        info!("ThreatHuntEngine stopped");
    }

    pub fn is_running(&self) -> bool { self.running.load(Ordering::SeqCst) }

    // ── Telemetry Ingestion ─────────────────────────────────────────────────

    /// Ingest telemetry records into the appropriate bounded ring buffer.
    pub fn ingest_telemetry(&self, source: DataSource, records: Vec<HashMap<String, String>>) {
        let count = records.len() as u64;
        let max = self.config.max_telemetry_per_source;

        let store: &RwLock<VecDeque<HashMap<String, String>>> = match source {
            DataSource::ProcessTelemetry | DataSource::CommandLine
            | DataSource::LoadedModules | DataSource::ScheduledTasks => &self.telemetry_process,
            DataSource::NetworkTelemetry | DataSource::DnsTelemetry => &self.telemetry_network,
            DataSource::AuthLogs => &self.telemetry_auth,
            DataSource::RegistryTelemetry | DataSource::ServiceChanges => &self.telemetry_registry,
            DataSource::FileTelemetry | DataSource::FileHashes => &self.telemetry_file,
        };

        {
            let mut s = store.write();
            for record in records {
                s.push_back(record);
            }
            while s.len() > max { s.pop_front(); }
        }

        self.stats.write().records_searched += count;
        debug!("Ingested {} {:?} records", count, source);
    }

    // ── IOC Database Management ─────────────────────────────────────────────

    /// Load IOCs into the sweep database for fast lookup.
    pub fn load_iocs(&self, ioc_type: IocType, values: Vec<String>) {
        let count = values.len();
        let mut db = self.ioc_database.write();
        let set = db.entry(ioc_type).or_insert_with(HashSet::new);
        for v in values { set.insert(v.to_lowercase()); }
        info!("Loaded {} {:?} IOCs (total: {})", count, ioc_type, set.len());
    }

    // ── Hunt Creation ───────────────────────────────────────────────────────

    /// Create a new hunt and return its ID.
    pub fn create_hunt(&self, mut hunt: Hunt) -> String {
        let now = chrono::Utc::now().timestamp();
        if hunt.id.is_empty() { hunt.id = uuid::Uuid::new_v4().to_string(); }
        hunt.created_at = now;
        hunt.status = HuntStatus::Draft;
        let id = hunt.id.clone();

        self.hunt_diffs.write().record_insert(
            id.clone(),
            serde_json::to_string(&hunt).unwrap_or_default(),
        );
        self.hunts.write().insert(id.clone(), hunt);
        self.stats.write().total_hunts += 1;
        info!("Created hunt {}", id);
        id
    }

    // ── Hunt Execution ──────────────────────────────────────────────────────

    /// Start and execute a hunt, returning all findings.
    pub fn start_hunt(&self, hunt_id: &str) -> Vec<HuntFinding> {
        let now = chrono::Utc::now().timestamp();
        let mut all_findings = Vec::new();

        let (queries, hunt_type, mitre_techs) = {
            let mut hunts = self.hunts.write();
            if let Some(hunt) = hunts.get_mut(hunt_id) {
                hunt.status = HuntStatus::Active;
                hunt.started_at = Some(now);
                hunt.run_count += 1;
                (hunt.queries.clone(), hunt.hunt_type, hunt.mitre_techniques.clone())
            } else {
                warn!("Hunt {} not found", hunt_id);
                return all_findings;
            }
        };

        self.stats.write().active_hunts += 1;

        for query in &queries {
            self.total_queries.fetch_add(1, Ordering::Relaxed);
            let results = self.execute_query(query);

            for record in &results {
                if all_findings.len() >= self.config.max_findings_per_hunt { break; }

                let severity = self.assess_severity(&record, hunt_type);
                let confidence = self.compute_confidence(&record, &query.filter);
                let evidence_hash = blake3::hash(
                    serde_json::to_string(&record).unwrap_or_default().as_bytes()
                ).to_hex().to_string();

                let finding = HuntFinding {
                    id: uuid::Uuid::new_v4().to_string(),
                    hunt_id: hunt_id.to_string(),
                    severity, confidence,
                    title: format!("Hunt match: {}", query.description),
                    description: format!(
                        "Query '{}' on {:?} matched {} records",
                        query.description, query.data_source, results.len()
                    ),
                    evidence: vec![Evidence {
                        evidence_type: "telemetry_match".into(),
                        source: query.data_source,
                        data: record.clone(),
                        timestamp: now,
                        hash: Some(evidence_hash),
                        preserved: self.config.evidence_preservation,
                        custody_chain: vec![format!("collected:threat_hunt_engine:{}", now)],
                    }],
                    mitre_technique: mitre_techs.first().cloned(),
                    timestamp: now,
                    affected_assets: record.get("hostname").into_iter().cloned().collect(),
                    recommended_actions: vec!["Investigate and validate finding".into()],
                    false_positive: false,
                    escalated: severity == FindingSeverity::Critical
                        && self.config.auto_escalate_critical,
                    related_finding_ids: vec![],
                };

                let fid = finding.id.clone();
                self.finding_cache.insert(fid.clone(), finding.clone());
                self.finding_dedup.write().insert(fid.clone(), vec![]);
                self.recent_findings.write().insert_with_priority(
                    fid, finding.clone(), confidence,
                );

                // Update technique × source matrix
                if let Some(tech) = &finding.mitre_technique {
                    let src = format!("{:?}", query.data_source);
                    let cur = *self.technique_source_matrix.read().get(tech, &src);
                    self.technique_source_matrix.write().set(tech.clone(), src, cur + 1);
                }

                all_findings.push(finding);
            }
        }

        // Complete hunt
        let duration_secs = chrono::Utc::now().timestamp() - now;
        {
            let mut hunts = self.hunts.write();
            if let Some(hunt) = hunts.get_mut(hunt_id) {
                hunt.status = HuntStatus::Completed;
                hunt.completed_at = Some(chrono::Utc::now().timestamp());
                hunt.findings = all_findings.clone();
                hunt.records_searched = self.stats.read().records_searched;
            }
        }

        {
            let mut stats = self.stats.write();
            stats.active_hunts = stats.active_hunts.saturating_sub(1);
            stats.completed_hunts += 1;
            stats.total_findings += all_findings.len() as u64;
            stats.total_queries_executed += queries.len() as u64;
            stats.critical_findings += all_findings.iter()
                .filter(|f| matches!(f.severity, FindingSeverity::Critical)).count() as u64;
            stats.high_findings += all_findings.iter()
                .filter(|f| matches!(f.severity, FindingSeverity::High)).count() as u64;
            stats.escalated_findings += all_findings.iter()
                .filter(|f| f.escalated).count() as u64;
            let type_key = format!("{:?}", hunt_type);
            *stats.hunts_by_type.entry(type_key).or_insert(0) += 1;
        }

        self.hunt_rate.write().push(all_findings.len() as f64);
        info!("Hunt {} completed in {}s: {} findings", hunt_id, duration_secs, all_findings.len());
        all_findings
    }

    // ── IOC Sweep ───────────────────────────────────────────────────────────

    /// Sweep all telemetry for loaded IOCs. Returns hits as findings.
    pub fn ioc_sweep(&self, hunt_id: &str) -> Vec<HuntFinding> {
        let now = chrono::Utc::now().timestamp();
        let db = self.ioc_database.read();
        let mut findings = Vec::new();

        // Build lookup sets for the fields we can match
        let hash_iocs = db.get(&IocType::Sha256)
            .cloned().unwrap_or_default();
        let domain_iocs = db.get(&IocType::Domain)
            .cloned().unwrap_or_default();
        let ip_iocs = db.get(&IocType::Ipv4)
            .cloned().unwrap_or_default();
        let filename_iocs = db.get(&IocType::Filename)
            .cloned().unwrap_or_default();

        // Sweep process telemetry
        for record in self.telemetry_process.read().iter() {
            let mut matched_ioc = None;
            if let Some(name) = record.get("process_name") {
                let nl = name.to_lowercase();
                if filename_iocs.contains(&nl) {
                    matched_ioc = Some(("filename", nl));
                }
            }
            if matched_ioc.is_none() {
                if let Some(hash) = record.get("hash") {
                    let hl = hash.to_lowercase();
                    if hash_iocs.contains(&hl) {
                        matched_ioc = Some(("sha256", hl));
                    }
                }
            }

            if let Some((ioc_kind, ioc_val)) = matched_ioc {
                findings.push(HuntFinding {
                    id: uuid::Uuid::new_v4().to_string(),
                    hunt_id: hunt_id.to_string(),
                    severity: FindingSeverity::High,
                    title: format!("IOC hit: {} = {}", ioc_kind, ioc_val),
                    description: format!("Process telemetry matched {} IOC", ioc_kind),
                    evidence: vec![Evidence {
                        evidence_type: "ioc_hit".into(),
                        source: DataSource::ProcessTelemetry,
                        data: record.clone(),
                        timestamp: now,
                        hash: Some(blake3::hash(ioc_val.as_bytes()).to_hex().to_string()),
                        preserved: true,
                        custody_chain: vec![format!("ioc_sweep:{}", now)],
                    }],
                    mitre_technique: None,
                    confidence: 0.9,
                    timestamp: now,
                    affected_assets: record.get("hostname").into_iter().cloned().collect(),
                    recommended_actions: vec![
                        "Isolate affected host".into(),
                        "Collect forensic image".into(),
                    ],
                    false_positive: false,
                    escalated: true,
                    related_finding_ids: vec![],
                });
            }
        }

        // Sweep network telemetry
        for record in self.telemetry_network.read().iter() {
            let mut matched_ioc = None;
            if let Some(dst) = record.get("dst_ip") {
                if ip_iocs.contains(&dst.to_lowercase()) {
                    matched_ioc = Some(("ipv4", dst.clone()));
                }
            }
            if matched_ioc.is_none() {
                if let Some(domain) = record.get("domain") {
                    if domain_iocs.contains(&domain.to_lowercase()) {
                        matched_ioc = Some(("domain", domain.clone()));
                    }
                }
            }
            if let Some((kind, val)) = matched_ioc {
                findings.push(HuntFinding {
                    id: uuid::Uuid::new_v4().to_string(),
                    hunt_id: hunt_id.to_string(),
                    severity: FindingSeverity::Critical,
                    title: format!("IOC hit: {} = {}", kind, val),
                    description: format!("Network telemetry matched {} IOC", kind),
                    evidence: vec![Evidence {
                        evidence_type: "ioc_hit".into(),
                        source: DataSource::NetworkTelemetry,
                        data: record.clone(),
                        timestamp: now,
                        hash: None, preserved: true,
                        custody_chain: vec![format!("ioc_sweep:{}", now)],
                    }],
                    mitre_technique: Some("T1071".into()),
                    confidence: 0.95,
                    timestamp: now,
                    affected_assets: record.get("src_ip").into_iter().cloned().collect(),
                    recommended_actions: vec![
                        "Block destination IP/domain".into(),
                        "Investigate source host".into(),
                    ],
                    false_positive: false, escalated: true,
                    related_finding_ids: vec![],
                });
            }
        }

        self.stats.write().ioc_sweeps_completed += 1;
        info!("IOC sweep completed: {} hits", findings.len());
        findings
    }

    // ── Stacking Analysis ───────────────────────────────────────────────────

    /// Stacking analysis: frequency count a field, identify rare values.
    /// Uses modified Z-score to quantify how unusual each value is.
    pub fn stack_analysis(&self, source: DataSource, field: &str, rare_pct: f64) -> Vec<StackingResult> {
        let store = self.get_telemetry_store(source);

        let mut counts: HashMap<String, (u64, i64, i64, HashSet<String>)> = HashMap::new();
        let total = store.len() as f64;

        for record in store.iter() {
            if let Some(value) = record.get(field) {
                let ts = record.get("timestamp")
                    .and_then(|t| t.parse::<i64>().ok()).unwrap_or(0);
                let asset = record.get("hostname").cloned().unwrap_or_default();
                let e = counts.entry(value.clone()).or_insert((0, i64::MAX, 0, HashSet::new()));
                e.0 += 1;
                if ts > 0 && ts < e.1 { e.1 = ts; }
                if ts > e.2 { e.2 = ts; }
                e.3.insert(asset);
            }
        }

        // Compute mean and std dev of counts for Z-score
        let count_values: Vec<f64> = counts.values().map(|c| c.0 as f64).collect();
        let (mean, std_dev) = Self::mean_stddev(&count_values);

        let mut results: Vec<StackingResult> = counts.into_iter().map(|(value, (count, first, last, assets))| {
            let pct = if total > 0.0 { count as f64 / total * 100.0 } else { 0.0 };
            let z_score = if std_dev > 0.0 { (count as f64 - mean) / std_dev } else { 0.0 };
            StackingResult {
                field: field.to_string(), value, count, percentage: pct,
                is_rare: pct <= rare_pct,
                z_score,
                first_seen: if first == i64::MAX { 0 } else { first },
                last_seen: last,
                associated_assets: assets.into_iter().collect(),
            }
        }).collect();

        results.sort_by(|a, b| a.count.cmp(&b.count));
        self.stats.write().stacking_analyses += 1;
        debug!("Stacking on '{}': {} unique values, {} rare", field, results.len(),
            results.iter().filter(|r| r.is_rare).count());
        results
    }

    // ── Long-Tail Analysis ──────────────────────────────────────────────────

    /// Long-tail analysis using Median Absolute Deviation (MAD) to find
    /// statistical outliers that are resilient to skewed distributions.
    pub fn long_tail_analysis(&self, source: DataSource, field: &str) -> Vec<LongTailResult> {
        let store = self.get_telemetry_store(source);

        let mut counts: HashMap<String, (u64, HashSet<String>)> = HashMap::new();
        for record in store.iter() {
            if let Some(value) = record.get(field) {
                let asset = record.get("hostname").cloned().unwrap_or_default();
                let e = counts.entry(value.clone()).or_insert((0, HashSet::new()));
                e.0 += 1;
                e.1.insert(asset);
            }
        }

        let count_values: Vec<f64> = counts.values().map(|c| c.0 as f64).collect();
        if count_values.is_empty() { return vec![]; }

        // Compute median
        let median = Self::median(&count_values);
        // Compute MAD (Median Absolute Deviation)
        let deviations: Vec<f64> = count_values.iter().map(|v| (v - median).abs()).collect();
        let mad = Self::median(&deviations);
        // Modified Z-score: 0.6745 * (xi - median) / MAD
        let mad_scale = if mad > 0.0 { mad } else { 1.0 };

        let threshold = self.config.long_tail_zscore_threshold;

        let mut results: Vec<LongTailResult> = counts.into_iter().map(|(value, (count, assets))| {
            let z = 0.6745 * (count as f64 - median) / mad_scale;
            LongTailResult {
                field: field.to_string(), value, count,
                z_score: z,
                is_outlier: z.abs() > threshold,
                median_count: median,
                mad: mad_scale,
                associated_assets: assets.into_iter().collect(),
            }
        }).collect();

        // Sort by absolute Z-score descending (most anomalous first)
        results.sort_by(|a, b| b.z_score.abs().partial_cmp(&a.z_score.abs()).unwrap_or(std::cmp::Ordering::Equal));
        self.stats.write().long_tail_analyses += 1;
        debug!("Long-tail on '{}': {} outliers of {} values",
            field, results.iter().filter(|r| r.is_outlier).count(), results.len());
        results
    }

    // ── Playbook Management ─────────────────────────────────────────────────

    /// Register a hunt playbook for a MITRE technique.
    pub fn register_playbook(&self, playbook: HuntPlaybook) {
        let id = playbook.id.clone();
        let tech = playbook.mitre_technique.clone();
        let tactic = playbook.mitre_tactic.clone();

        let cur = *self.technique_source_matrix.read().get(&tech, &tactic);
        self.technique_source_matrix.write().set(tech, tactic, cur + 1);
        self.playbooks.write().insert(id, playbook);
    }

    /// List all available playbooks.
    pub fn list_playbooks(&self) -> Vec<HuntPlaybook> {
        self.playbooks.read().values().cloned().collect()
    }

    /// Execute a playbook as a hunt.
    pub fn execute_playbook(&self, playbook_id: &str, analyst: &str) -> Option<Vec<HuntFinding>> {
        let playbook = self.playbooks.read().get(playbook_id)?.clone();

        let hunt = Hunt {
            id: String::new(),
            name: playbook.name.clone(),
            description: playbook.description.clone(),
            hunt_type: HuntType::MitrePlaybook,
            status: HuntStatus::Draft,
            hypothesis: Some(playbook.hypothesis.clone()),
            data_sources: playbook.data_sources_required.clone(),
            queries: playbook.queries.clone(),
            mitre_techniques: vec![playbook.mitre_technique.clone()],
            created_at: 0, started_at: None, completed_at: None,
            analyst: analyst.to_string(),
            findings: vec![], artifacts_collected: 0, records_searched: 0,
            tags: vec![format!("playbook:{}", playbook_id)],
            schedule_cron: None, last_run: None, run_count: 0, ioc_list: vec![],
        };

        let hunt_id = self.create_hunt(hunt);
        Some(self.start_hunt(&hunt_id))
    }

    // ── Suspicious Process Scan ─────────────────────────────────────────────

    /// Quick scan for known suspicious process names in telemetry.
    pub fn scan_suspicious_processes(&self) -> Vec<HuntFinding> {
        let now = chrono::Utc::now().timestamp();
        let mut findings = Vec::new();
        let store = self.telemetry_process.read();

        for record in store.iter() {
            if let Some(name) = record.get("process_name") {
                let nl = name.to_lowercase();
                if SUSPICIOUS_PROCESSES.iter().any(|s| nl.contains(s)) {
                    findings.push(HuntFinding {
                        id: uuid::Uuid::new_v4().to_string(),
                        hunt_id: "auto_suspicious_scan".into(),
                        severity: FindingSeverity::High,
                        title: format!("Suspicious process: {}", name),
                        description: format!(
                            "Process '{}' matches known offensive tool signature", name
                        ),
                        evidence: vec![Evidence {
                            evidence_type: "suspicious_process".into(),
                            source: DataSource::ProcessTelemetry,
                            data: record.clone(),
                            timestamp: now,
                            hash: None, preserved: true,
                            custody_chain: vec![format!("auto_scan:{}", now)],
                        }],
                        mitre_technique: Some("T1059".into()),
                        confidence: 0.8,
                        timestamp: now,
                        affected_assets: record.get("hostname").into_iter().cloned().collect(),
                        recommended_actions: vec![
                            "Verify process legitimacy".into(),
                            "Check parent process chain".into(),
                            "Collect memory dump".into(),
                        ],
                        false_positive: false, escalated: false,
                        related_finding_ids: vec![],
                    });
                }
            }
        }

        info!("Suspicious process scan: {} findings", findings.len());
        findings
    }

    // ── Mark Finding ────────────────────────────────────────────────────────

    /// Mark a finding as false positive or confirmed.
    pub fn mark_finding(&self, hunt_id: &str, finding_id: &str, false_positive: bool) {
        let mut hunts = self.hunts.write();
        if let Some(hunt) = hunts.get_mut(hunt_id) {
            for finding in &mut hunt.findings {
                if finding.id == finding_id {
                    finding.false_positive = false_positive;
                    if false_positive {
                        self.stats.write().false_positives += 1;
                    }
                    break;
                }
            }
        }
    }

    // ── Internal Helpers ────────────────────────────────────────────────────

    fn get_telemetry_store(&self, source: DataSource) -> parking_lot::RwLockReadGuard<'_, VecDeque<HashMap<String, String>>> {
        match source {
            DataSource::ProcessTelemetry | DataSource::CommandLine
            | DataSource::LoadedModules | DataSource::ScheduledTasks => self.telemetry_process.read(),
            DataSource::NetworkTelemetry | DataSource::DnsTelemetry => self.telemetry_network.read(),
            DataSource::AuthLogs => self.telemetry_auth.read(),
            DataSource::RegistryTelemetry | DataSource::ServiceChanges => self.telemetry_registry.read(),
            DataSource::FileTelemetry | DataSource::FileHashes => self.telemetry_file.read(),
        }
    }

    fn execute_query(&self, query: &HuntQuery) -> Vec<HashMap<String, String>> {
        let store = self.get_telemetry_store(query.data_source);

        let mut results: Vec<HashMap<String, String>> = store.iter()
            .filter(|record| self.matches_filter(record, &query.filter))
            .cloned()
            .collect();

        // Sort if requested
        if let Some(ref sort_field) = query.sort_by {
            let desc = query.sort_desc;
            results.sort_by(|a, b| {
                let va = a.get(sort_field).cloned().unwrap_or_default();
                let vb = b.get(sort_field).cloned().unwrap_or_default();
                let cmp = va.cmp(&vb);
                if desc { cmp.reverse() } else { cmp }
            });
        }

        if let Some(limit) = query.limit {
            results.truncate(limit as usize);
        }

        self.stats.write().total_queries_executed += 1;
        // Breakthrough #1: HierarchicalState — checkpoint stats at O(log n)
        self.hunt_history.write().checkpoint(self.stats.read().clone());
        // Breakthrough #3: ReversibleComputation — feed event into risk model
        self.score_computer.write().push(1.0f64);
        // Breakthrough #5: StreamAccumulator — accumulate event rate
        self.hunt_rate.write().push(1.0);
        results
    }

    fn matches_filter(&self, record: &HashMap<String, String>, filter: &QueryFilter) -> bool {
        if filter.field.is_empty() { return true; }
        let field_val = record.get(&filter.field).map(|s| s.as_str()).unwrap_or("");

        let ok = match filter.operator {
            FilterOp::Eq => field_val == filter.value,
            FilterOp::NotEq => field_val != filter.value,
            FilterOp::Contains => field_val.to_lowercase().contains(&filter.value.to_lowercase()),
            FilterOp::NotContains => !field_val.to_lowercase().contains(&filter.value.to_lowercase()),
            FilterOp::StartsWith => field_val.starts_with(&filter.value),
            FilterOp::EndsWith => field_val.ends_with(&filter.value),
            FilterOp::Regex => regex::Regex::new(&filter.value).map(|r| r.is_match(field_val)).unwrap_or(false),
            FilterOp::Gt => field_val.parse::<f64>().unwrap_or(0.0) > filter.value.parse::<f64>().unwrap_or(0.0),
            FilterOp::Lt => field_val.parse::<f64>().unwrap_or(0.0) < filter.value.parse::<f64>().unwrap_or(0.0),
            FilterOp::Gte => field_val.parse::<f64>().unwrap_or(0.0) >= filter.value.parse::<f64>().unwrap_or(0.0),
            FilterOp::Lte => field_val.parse::<f64>().unwrap_or(0.0) <= filter.value.parse::<f64>().unwrap_or(0.0),
            FilterOp::In => filter.value.split(',').any(|v| v.trim() == field_val),
            FilterOp::NotIn => !filter.value.split(',').any(|v| v.trim() == field_val),
            FilterOp::Exists => !field_val.is_empty(),
        };

        if !ok { return false; }
        if !filter.and_filters.is_empty()
            && !filter.and_filters.iter().all(|f| self.matches_filter(record, f)) { return false; }
        if !filter.or_filters.is_empty()
            && !filter.or_filters.iter().any(|f| self.matches_filter(record, f)) { return false; }
        true
    }

    /// Assess severity based on record content and hunt type.
    fn assess_severity(&self, record: &HashMap<String, String>, hunt_type: HuntType) -> FindingSeverity {
        let mut score = 0u32;

        // Check for suspicious process names
        if let Some(name) = record.get("process_name") {
            let nl = name.to_lowercase();
            if SUSPICIOUS_PROCESSES.iter().any(|s| nl.contains(s)) { score += 3; }
        }

        // Check for suspicious ports
        if let Some(port_str) = record.get("dst_port") {
            if let Ok(port) = port_str.parse::<u16>() {
                if SUSPICIOUS_PORTS.contains(&port) { score += 2; }
            }
        }

        // Escalate IOC sweep hits
        if hunt_type == HuntType::IocSweep { score += 2; }

        match score {
            0 => FindingSeverity::Low,
            1 => FindingSeverity::Medium,
            2..=3 => FindingSeverity::High,
            _ => FindingSeverity::Critical,
        }
    }

    /// Compute confidence score based on filter specificity and data richness.
    fn compute_confidence(&self, record: &HashMap<String, String>, filter: &QueryFilter) -> f64 {
        let mut conf = 0.5;

        // More specific filters = higher confidence
        conf += filter.and_filters.len() as f64 * 0.05;

        // Records with more fields = higher confidence
        let field_count = record.len();
        if field_count > 10 { conf += 0.1; }
        if field_count > 20 { conf += 0.1; }

        // Exact match operators = higher confidence
        if filter.operator == FilterOp::Eq { conf += 0.05; }
        if filter.operator == FilterOp::Regex { conf += 0.1; }

        conf.min(0.99)
    }

    /// Compute mean and standard deviation.
    fn mean_stddev(values: &[f64]) -> (f64, f64) {
        if values.is_empty() { return (0.0, 0.0); }
        let n = values.len() as f64;
        let mean = values.iter().sum::<f64>() / n;
        let variance = values.iter().map(|v| (v - mean).powi(2)).sum::<f64>() / n;
        (mean, variance.sqrt())
    }

    /// Compute median of a slice.
    fn median(values: &[f64]) -> f64 {
        if values.is_empty() { return 0.0; }
        let mut sorted = values.to_vec();
        sorted.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
        let mid = sorted.len() / 2;
        if sorted.len() % 2 == 0 {
            (sorted[mid - 1] + sorted[mid]) / 2.0
        } else {
            sorted[mid]
        }
    }

    // ── Accessors ───────────────────────────────────────────────────────────

    pub fn get_hunt(&self, id: &str) -> Option<Hunt> {
        self.hunts.read().get(id).cloned()
    }

    pub fn list_hunts(&self) -> Vec<Hunt> {
        self.hunts.read().values().cloned().collect()
    }

    pub fn stats(&self) -> HuntStats { self.stats.read().clone() }
    pub fn metrics(&self) -> &MemoryMetrics { &self.metrics }
}
