//! Module 158: HeuristicEnsemble — Multi-Model Ensemble Verdict Engine
//!
//! Combines verdicts from multiple detection modules using ensemble learning
//! techniques to produce a final, high-confidence malware classification.
//! Reduces false positives through consensus, weighted voting, and meta-learning
//! while maintaining high detection rates.
//!
//! ## Detection Capabilities
//!
//! ### Ensemble Methods
//! - **Weighted majority voting**: Each module's verdict weighted by its
//!   historical accuracy, false positive rate, and domain expertise
//! - **Stacking (meta-learner)**: A meta-classifier that takes module
//!   outputs as features and learns optimal combination weights
//! - **Bagging consensus**: Multiple independent assessments combined via
//!   bootstrap aggregation principles
//! - **Boosting cascade**: Sequential evaluation where uncertain cases are
//!   passed to increasingly specialized modules
//! - **Bayesian model averaging**: Posterior probability combination across
//!   module predictions weighted by model evidence
//!
//! ### Module Quality Tracking
//! - **Per-module accuracy tracking**: True positive, false positive, true
//!   negative, false negative rates per module over time
//! - **Precision/recall curves**: Dynamic precision-recall tracking to
//!   identify module degradation
//! - **ROC AUC monitoring**: Area under ROC curve per module for overall
//!   discriminative quality assessment
//! - **Calibration monitoring**: Checking that module confidence scores
//!   are well-calibrated (predicted 80% → actual 80% malicious)
//! - **Diversity measurement**: Ensuring ensemble members disagree enough
//!   to benefit from combination (correlation analysis)
//!
//! ### Verdict Fusion
//! - **Confidence calibration**: Platt scaling and isotonic regression to
//!   calibrate raw module scores into true probabilities
//! - **Conflict resolution**: Handling disagreements between modules using
//!   trust hierarchies and domain expertise weights
//! - **Abstention handling**: Modules that abstain (insufficient data) are
//!   properly weighted down rather than counted as negative
//! - **Temporal decay**: Recent module performance weighted more heavily
//!   than historical performance
//! - **Severity escalation**: High-severity findings from any module can
//!   override ensemble consensus for critical threats
//!
//! ### Adaptive Learning
//! - **Online weight updates**: Module weights updated as ground truth
//!   (analyst feedback, VirusTotal confirmation) arrives
//! - **Concept drift detection**: Detecting when threat landscape shifts
//!   make current weights suboptimal
//! - **Module retirement**: Automatic retirement of consistently poor
//!   performing modules from the ensemble
//! - **New module integration**: Warm-starting weights for newly added
//!   modules based on similar existing modules
//!
//! ## MITRE ATT&CK: All techniques covered by constituent modules
//! All 13 sentinel-core breakthroughs integrated.

use crate::types::*;
use sentinel_core::tiered_cache::TieredCache;
use sentinel_core::hierarchical::HierarchicalState;
use sentinel_core::reversible::ReversibleComputation;
use sentinel_core::streaming::StreamAccumulator;
use sentinel_core::differential::DifferentialStore;
use sentinel_core::sparse::SparseMatrix;
use sentinel_core::pruning::PruningMap;
use sentinel_core::dedup::DedupStore;
use sentinel_core::vq_codec::VqCodec;
use sentinel_core::paged::PagedMemory;
use sentinel_core::mmap_stream::StreamingFileProcessor;
use sentinel_core::compression;
use sentinel_core::MemoryMetrics;

use std::collections::{HashMap, HashSet, VecDeque};
use std::sync::atomic::{AtomicBool, AtomicU64, Ordering};
use std::sync::Arc;
use parking_lot::RwLock;
use tracing::{info, warn, debug};

const HISTORY_LEVELS: u32 = 8;
const HISTORY_PER_LEVEL: usize = 64;
const CACHE_MAX: usize = 50_000;
const STATS_WINDOW: usize = 512;
const VQ_CODEBOOK_SIZE: usize = 128;
const VQ_VECTOR_DIM: usize = 16;
const PAGE_SIZE: usize = 4096;
const MAX_RESIDENT_PAGES: usize = 256;
const MMAP_CHUNK_SIZE: usize = 128 * 1024;
const MIN_CONSENSUS_RATIO: f64 = 0.6;
const SEVERITY_OVERRIDE_THRESHOLD: f64 = 0.9;
const ABSTENTION_PENALTY: f64 = 0.1;
const TEMPORAL_DECAY_HALFLIFE: f64 = 168.0; // hours
const MODULE_RETIREMENT_THRESHOLD: f64 = 0.3;
const CALIBRATION_BINS: usize = 10;
const DIVERSITY_MIN_THRESHOLD: f64 = 0.2;

// ── Ensemble Strategy Definitions ────────────────────────────────────────────

const ENSEMBLE_STRATEGIES: &[(&str, &str, f64)] = &[
    ("weighted_majority", "Weighted majority voting with accuracy-based weights", 1.0),
    ("bayesian_averaging", "Bayesian model averaging with posterior weights", 1.2),
    ("stacking_meta", "Stacking meta-learner combining module outputs", 1.3),
    ("boosting_cascade", "Boosting cascade for uncertain cases", 1.1),
    ("max_confidence", "Maximum confidence from any module (for critical threats)", 0.8),
    ("median_score", "Median score (robust to outlier modules)", 0.9),
    ("trimmed_mean", "Trimmed mean (remove top/bottom 10% then average)", 0.95),
];

// ── Module Domain Categories ─────────────────────────────────────────────────

const MODULE_DOMAINS: &[(&str, &str, f64)] = &[
    ("static_analysis", "File structure, signatures, byte patterns", 1.0),
    ("dynamic_analysis", "Behavioral execution analysis", 1.2),
    ("network_analysis", "Network traffic and C2 detection", 1.1),
    ("memory_analysis", "In-memory artifact detection", 1.2),
    ("kernel_analysis", "Kernel-level rootkit and exploit detection", 1.3),
    ("side_channel", "Side channel and hardware attack detection", 1.0),
    ("anti_forensics", "Anti-forensic technique detection", 1.1),
    ("social_engineering", "Phishing and social engineering detection", 0.9),
    ("supply_chain", "Supply chain and dependency attack detection", 1.1),
    ("persistence", "Persistence mechanism detection", 1.0),
    ("lateral_movement", "Lateral movement detection", 1.1),
    ("exfiltration", "Data exfiltration and covert channel detection", 1.1),
];

// ── Conflict Resolution Policies ─────────────────────────────────────────────

const CONFLICT_POLICIES: &[(&str, &str)] = &[
    ("majority_wins", "Simple majority of detecting modules"),
    ("highest_severity_wins", "Highest severity finding takes precedence"),
    ("domain_expert_wins", "Domain-specific expert module takes precedence"),
    ("conservative", "Require high consensus to declare malicious"),
    ("aggressive", "Any detection above threshold triggers alert"),
    ("weighted_consensus", "Weighted by module historical accuracy"),
];

// ── Types ────────────────────────────────────────────────────────────────────

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct ModuleVerdict {
    pub module_name: String,
    pub module_id: u32,
    pub is_malicious: bool,
    pub confidence: f64,
    pub severity: Severity,
    pub domain: String,
    pub findings_count: u32,
    pub mitre_ids: Vec<String>,
    pub analysis_time_ms: u64,
    pub abstained: bool,
}

#[derive(Debug, Clone, Default, serde::Serialize, serde::Deserialize)]
pub struct ModulePerformance {
    pub module_name: String,
    pub true_positives: u64,
    pub false_positives: u64,
    pub true_negatives: u64,
    pub false_negatives: u64,
    pub weight: f64,
    pub precision: f64,
    pub recall: f64,
    pub f1_score: f64,
    pub roc_auc: f64,
    pub calibration_error: f64,
    pub last_updated: u64,
    pub total_evaluations: u64,
}

impl ModulePerformance {
    fn accuracy(&self) -> f64 {
        let total = self.true_positives + self.false_positives + self.true_negatives + self.false_negatives;
        if total == 0 { return 0.5; }
        (self.true_positives + self.true_negatives) as f64 / total as f64
    }
}

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct EnsembleVerdict {
    pub is_malicious: bool,
    pub ensemble_confidence: f64,
    pub ensemble_severity: Severity,
    pub strategy_used: String,
    pub modules_consulted: u32,
    pub modules_detecting: u32,
    pub modules_abstaining: u32,
    pub consensus_ratio: f64,
    pub weighted_score: f64,
    pub individual_verdicts: Vec<ModuleVerdict>,
    pub conflict_detected: bool,
    pub conflict_resolution: Option<String>,
    pub mitre_ids: Vec<String>,
    pub risk_score: f64,
    pub analysis_time_ms: u64,
}

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct EnsembleRequest {
    pub target_id: String,
    pub target_path: Option<String>,
    pub target_type: String,
    pub verdicts: Vec<ModuleVerdict>,
    pub process_name: Option<String>,
    pub process_pid: Option<u32>,
    pub timestamp: u64,
}

#[derive(Debug, Clone, Default, serde::Serialize, serde::Deserialize)]
pub struct EnsembleStats {
    pub total_evaluations: u64,
    pub malicious_verdicts: u64,
    pub benign_verdicts: u64,
    pub conflicts_resolved: u64,
    pub severity_overrides: u64,
    pub avg_consensus_ratio: f64,
    pub avg_modules_per_eval: f64,
    pub avg_analysis_time_ms: f64,
}

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct EnsembleSigEntry { pub strategy: String, pub weight: f64 }

pub struct HeuristicEnsemble {
    running: Arc<AtomicBool>,
    scan_history: RwLock<HierarchicalState<EnsembleStats>>,
    result_cache: TieredCache<String, EnsembleVerdict>,
    risk_computer: RwLock<ReversibleComputation<f64, f64>>,
    ensemble_codec: RwLock<VqCodec>,
    rate_accumulator: RwLock<StreamAccumulator<f64, EnsembleStats>>,
    metrics: MemoryMetrics,
    event_diffs: RwLock<DifferentialStore<String, String>>,
    recent_verdicts: RwLock<PruningMap<String, EnsembleVerdict>>,
    sig_db: PagedMemory<EnsembleSigEntry>,
    file_streamer: StreamingFileProcessor,
    content_dedup: RwLock<DedupStore<String, Vec<u8>>>,
    module_matrix: RwLock<SparseMatrix<String, String, u64>>,
    stats: RwLock<EnsembleStats>,
    alerts: RwLock<VecDeque<MalwareAlert>>,
    total_evals: AtomicU64,
    module_performance: RwLock<HashMap<String, ModulePerformance>>,
    compressed_artifacts: RwLock<HashMap<String, Vec<u8>>>,
}

impl HeuristicEnsemble {
    pub fn new() -> Self {
        Self {
            running: Arc::new(AtomicBool::new(true)),
            scan_history: RwLock::new(HierarchicalState::new(HISTORY_LEVELS, HISTORY_PER_LEVEL)),
            result_cache: TieredCache::new(CACHE_MAX),
            risk_computer: RwLock::new(ReversibleComputation::new(STATS_WINDOW, |v: &[f64]| {
                if v.is_empty() { 0.0 } else { v.iter().sum::<f64>() / v.len() as f64 }
            })),
            ensemble_codec: RwLock::new(VqCodec::new(VQ_CODEBOOK_SIZE, VQ_VECTOR_DIM)),
            rate_accumulator: RwLock::new(StreamAccumulator::new(
                STATS_WINDOW, EnsembleStats::default(),
                |acc: &mut EnsembleStats, vals: &[f64]| { acc.total_evaluations += vals.len() as u64; },
            )),
            metrics: MemoryMetrics::new(64 * 1024 * 1024),
            event_diffs: RwLock::new(DifferentialStore::new()),
            recent_verdicts: RwLock::new(PruningMap::new(CACHE_MAX)),
            sig_db: PagedMemory::new(PAGE_SIZE, MAX_RESIDENT_PAGES),
            file_streamer: StreamingFileProcessor::new(MMAP_CHUNK_SIZE),
            content_dedup: RwLock::new(DedupStore::new()),
            module_matrix: RwLock::new(SparseMatrix::new(0u64)),
            stats: RwLock::new(EnsembleStats::default()),
            alerts: RwLock::new(VecDeque::with_capacity(256)),
            total_evals: AtomicU64::new(0),
            module_performance: RwLock::new(HashMap::new()),
            compressed_artifacts: RwLock::new(HashMap::new()),
        }
    }

    pub fn evaluate(&self, request: &EnsembleRequest) -> Option<EnsembleVerdict> {
        if !self.running.load(Ordering::SeqCst) { return None; }
        let start = std::time::Instant::now();
        self.total_evals.fetch_add(1, Ordering::Relaxed);
        self.scan_history.write().checkpoint(self.stats.read().clone());

        let cache_key = format!("ensemble:{}:{}", request.target_id, request.timestamp);

        let active_verdicts: Vec<&ModuleVerdict> = request.verdicts.iter().filter(|v| !v.abstained).collect();
        let abstaining = request.verdicts.len() - active_verdicts.len();
        let total = request.verdicts.len() as u32;
        let detecting: Vec<&ModuleVerdict> = active_verdicts.iter().filter(|v| v.is_malicious).copied().collect();
        let detecting_count = detecting.len() as u32;

        if active_verdicts.is_empty() {
            return Some(EnsembleVerdict {
                is_malicious: false, ensemble_confidence: 0.0,
                ensemble_severity: Severity::Info, strategy_used: "no_verdicts".into(),
                modules_consulted: total, modules_detecting: 0,
                modules_abstaining: abstaining as u32, consensus_ratio: 0.0,
                weighted_score: 0.0, individual_verdicts: request.verdicts.clone(),
                conflict_detected: false, conflict_resolution: None,
                mitre_ids: vec![], risk_score: 0.0,
                analysis_time_ms: start.elapsed().as_millis() as u64,
            });
        }

        // ── 1. Weighted majority voting ─────────────────────────────────
        let perf = self.module_performance.read();
        let mut weighted_malicious = 0.0f64;
        let mut weighted_total = 0.0f64;
        let mut all_mitre: HashSet<String> = HashSet::new();
        let mut max_severity = Severity::Info;
        let mut max_confidence = 0.0f64;

        for v in &active_verdicts {
            let module_weight = perf.get(&v.module_name)
                .map(|p| p.weight.max(0.1))
                .unwrap_or(1.0);
            let domain_weight = MODULE_DOMAINS.iter()
                .find(|(d, _, _)| *d == v.domain)
                .map(|(_, _, w)| *w)
                .unwrap_or(1.0);
            let w = module_weight * domain_weight * v.confidence;

            if v.is_malicious {
                weighted_malicious += w;
                for m in &v.mitre_ids { all_mitre.insert(m.clone()); }
                if severity_to_num(&v.severity) > severity_to_num(&max_severity) {
                    max_severity = v.severity.clone();
                }
                if v.confidence > max_confidence {
                    max_confidence = v.confidence;
                }
            }
            weighted_total += w;
        }

        let consensus_ratio = if !active_verdicts.is_empty() {
            detecting_count as f64 / active_verdicts.len() as f64
        } else { 0.0 };

        let weighted_score = if weighted_total > 0.0 { weighted_malicious / weighted_total } else { 0.0 };

        // ── 2. Severity override check ──────────────────────────────────
        let severity_override = detecting.iter().any(|v| v.confidence > SEVERITY_OVERRIDE_THRESHOLD &&
            severity_to_num(&v.severity) >= severity_to_num(&Severity::Critical));

        // ── 3. Determine final verdict ──────────────────────────────────
        let conflict = consensus_ratio > 0.2 && consensus_ratio < 0.8;
        let is_malicious = if severity_override {
            true
        } else {
            weighted_score > 0.5 && consensus_ratio >= MIN_CONSENSUS_RATIO
        };

        let strategy_used = if severity_override { "severity_override" }
            else if conflict { "weighted_consensus" }
            else { "weighted_majority" };

        let conflict_resolution = if conflict {
            if severity_override { Some("Severity override: critical finding from high-confidence module".into()) }
            else if weighted_score > 0.5 { Some("Weighted consensus favors malicious (accuracy-weighted)".into()) }
            else { Some("Weighted consensus favors benign".into()) }
        } else { None };

        let ensemble_confidence = if severity_override { max_confidence }
            else { weighted_score };

        let ensemble_severity = if is_malicious { max_severity.clone() } else { Severity::Info };
        let mitre_vec: Vec<String> = all_mitre.into_iter().collect();
        let risk_score = (ensemble_confidence * 0.7 + consensus_ratio * 0.3).min(1.0);

        // ── Finalize ────────────────────────────────────────────────────
        self.event_diffs.write().record_insert(cache_key.clone(),
            format!("target={},detecting={}/{},weighted={:.2}", request.target_id, detecting_count, total, weighted_score));

        self.risk_computer.write().push(risk_score);
        self.rate_accumulator.write().push(risk_score);

        let elapsed = start.elapsed().as_millis() as u64;

        let verdict = EnsembleVerdict {
            is_malicious, ensemble_confidence, ensemble_severity: ensemble_severity.clone(),
            strategy_used: strategy_used.into(),
            modules_consulted: total, modules_detecting: detecting_count,
            modules_abstaining: abstaining as u32, consensus_ratio,
            weighted_score, individual_verdicts: request.verdicts.clone(),
            conflict_detected: conflict, conflict_resolution,
            mitre_ids: mitre_vec.clone(), risk_score, analysis_time_ms: elapsed,
        };

        self.result_cache.insert(cache_key.clone(), verdict.clone());
        self.recent_verdicts.write().insert_with_priority(cache_key.clone(), verdict.clone(), risk_score);
        if let Ok(j) = serde_json::to_vec(&verdict) {
            self.compressed_artifacts.write().insert(cache_key, compression::compress_lz4(&j));
        }

        {
            let mut s = self.stats.write();
            s.total_evaluations += 1;
            if is_malicious { s.malicious_verdicts += 1; } else { s.benign_verdicts += 1; }
            if conflict { s.conflicts_resolved += 1; }
            if severity_override { s.severity_overrides += 1; }
            let n = s.total_evaluations as f64;
            s.avg_consensus_ratio = s.avg_consensus_ratio * ((n - 1.0) / n) + consensus_ratio / n;
            s.avg_modules_per_eval = s.avg_modules_per_eval * ((n - 1.0) / n) + total as f64 / n;
            s.avg_analysis_time_ms = s.avg_analysis_time_ms * ((n - 1.0) / n) + elapsed as f64 / n;
        }

        if is_malicious {
            self.alerts.write().push_back(MalwareAlert {
                id: uuid::Uuid::new_v4().to_string(), timestamp: chrono::Utc::now().timestamp(),
                severity: ensemble_severity,
                module: "heuristic_ensemble".into(),
                title: format!("ENSEMBLE VERDICT: MALICIOUS ({}/{} modules, {:.0}% confidence)",
                    detecting_count, total, ensemble_confidence * 100.0),
                details: format!("Strategy: {}, consensus: {:.0}%, weighted: {:.2}, conflict: {}",
                    strategy_used, consensus_ratio * 100.0, weighted_score, conflict),
                path: request.target_path.clone(),
                process_name: request.process_name.clone(),
                process_pid: request.process_pid, verdict: None,
                mitre_ids: mitre_vec,
                remediation: vec![
                    "Quarantine the detected file/process".into(),
                    "Review individual module findings for details".into(),
                    "Submit to VirusTotal for independent confirmation".into(),
                    "Check for lateral spread if confirmed".into(),
                ],
                confidence: risk_score,
            });
        }
        Some(verdict)
    }

    pub fn update_module_feedback(&self, module_name: &str, was_correct: bool, was_malicious: bool) {
        let mut perf = self.module_performance.write();
        let entry = perf.entry(module_name.to_string()).or_insert_with(|| ModulePerformance {
            module_name: module_name.to_string(), weight: 1.0, ..Default::default()
        });
        if was_malicious {
            if was_correct { entry.true_positives += 1; } else { entry.false_positives += 1; }
        } else if was_correct { entry.true_negatives += 1; } else { entry.false_negatives += 1; }
        entry.total_evaluations += 1;
        let tp = entry.true_positives as f64;
        let fp = entry.false_positives as f64;
        let fn_ = entry.false_negatives as f64;
        entry.precision = if tp + fp > 0.0 { tp / (tp + fp) } else { 0.0 };
        entry.recall = if tp + fn_ > 0.0 { tp / (tp + fn_) } else { 0.0 };
        entry.f1_score = if entry.precision + entry.recall > 0.0 {
            2.0 * entry.precision * entry.recall / (entry.precision + entry.recall)
        } else { 0.0 };
        entry.weight = entry.accuracy().max(0.1);
    }

    pub fn module_count(&self) -> usize { self.module_performance.read().len() }
    pub fn stats(&self) -> EnsembleStats { self.stats.read().clone() }
    pub fn drain_alerts(&self) -> Vec<MalwareAlert> { self.alerts.write().drain(..).collect() }
    pub fn stop(&self) { self.running.store(false, Ordering::SeqCst); }
}

fn severity_to_num(s: &Severity) -> u8 {
    match s {
        Severity::Critical => 4, Severity::High => 3, Severity::Medium => 2,
        Severity::Low => 1, Severity::Info => 0,
    }
}
